{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "192Av6nSvgP6NJTWiceP1xasULGdr7X7L",
      "authorship_tag": "ABX9TyMRLjyBP0DRIJGm8IhHXv4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunhaday/AIFFEL_quest_cr/blob/master/MainQuest/QUEST03/0906_prj01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ33gHxPWqml",
        "outputId": "b5ff38ee-7d64-46fb-c547-5c46644b30d3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3.2\n",
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            "|details-start|\n",
            "**References**\n",
            "|details-split|\n",
            "\n",
            "- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "  Graduate Studies in Science and Engineering, Bogazici University.\n",
            "- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "  Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "  Electrical and Electronic Engineering Nanyang Technological University.\n",
            "  2005.\n",
            "- Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "  Algorithm. NIPS. 2000.\n",
            "\n",
            "|details-end|\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.81      0.81      0.81        42\n",
            "           2       0.79      0.82      0.80        40\n",
            "           3       0.79      0.91      0.85        34\n",
            "           4       0.83      0.95      0.89        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       0.84      0.93      0.88        28\n",
            "           7       0.96      0.82      0.89        33\n",
            "           8       0.88      0.65      0.75        43\n",
            "           9       0.78      0.78      0.78        32\n",
            "\n",
            "    accuracy                           0.86       360\n",
            "   macro avg       0.86      0.86      0.86       360\n",
            "weighted avg       0.86      0.86      0.85       360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "# (1) 필요한 모듈 import\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.model_selection import train_test_split #싸이킷런에 있는 데이터를 train과 test dataset으로 나누어주는 함수 import\n",
        "from sklearn.tree import DecisionTreeClassifier # 싸이킷런에 있는 결정트리분류기를 사용하기 위해 불러오는 코드\n",
        "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위해 쓰는 코드\n",
        "\n",
        "\n",
        "# (2) 데이터 준비\n",
        "digits = load_digits() #digits 데이터 전체를 불러온다.\n",
        "digits.keys()\n",
        "\n",
        "# (3) 데이터 이해하기\n",
        "digits_data = digits.data #Feature Data 지정하기\n",
        "digits_label = digits.target #Label Data 지정하기\n",
        "\n",
        "digits.target_names #Target Names 출력해 보기\n",
        "print(digits.DESCR) #데이터 Describe 해 보기\n",
        "\n",
        "\n",
        "# (4) train, test 데이터 분리\n",
        "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
        "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다. (어떤 값을 넣어도 무방하다.)\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
        "                                                    digits_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=7)\n",
        "\n",
        "\n",
        "# (5) 모델 학습 및 예측\n",
        "decision_tree = DecisionTreeClassifier(random_state=32) #결정트리분류기의 객체를 만든다.\n",
        "decision_tree.fit(X_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
        "y_pred = decision_tree.predict(X_test) # 훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인한다.\n",
        "\n",
        "print(classification_report(y_test, y_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "# (1) 필요한 모듈 import\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.model_selection import train_test_split #싸이킷런에 있는 데이터를 train과 test dataset으로 나누어주는 함수 import\n",
        "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위해 import\n",
        "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위해 쓰는 코드\n",
        "\n",
        "\n",
        "# (2) 데이터 준비\n",
        "digits = load_digits() #digits 데이터 전체를 불러온다.\n",
        "digits.keys()\n",
        "\n",
        "# (3) 데이터 이해하기\n",
        "digits_data = digits.data #Feature Data 지정하기\n",
        "digits_label = digits.target #Label Data 지정하기\n",
        "\n",
        "digits.target_names #Target Names 출력해 보기\n",
        "print(digits.DESCR) #데이터 Describe 해 보기\n",
        "\n",
        "\n",
        "# (4) train, test 데이터 분리\n",
        "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
        "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다. (어떤 값을 넣어도 무방하다.)\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
        "                                                    digits_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=7)\n",
        "\n",
        "\n",
        "# (5) 모델 학습 및 예측\n",
        "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
        "random_forest.fit(X_train, y_train) # 훈련\n",
        "y_pred = random_forest.predict(X_test) # 예측\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY6BQMD3XEG5",
        "outputId": "931ce147-01cb-4d08-b855-c2781a0f0154"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n",
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            "|details-start|\n",
            "**References**\n",
            "|details-split|\n",
            "\n",
            "- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "  Graduate Studies in Science and Engineering, Bogazici University.\n",
            "- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "  Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "  Electrical and Electronic Engineering Nanyang Technological University.\n",
            "  2005.\n",
            "- Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "  Algorithm. NIPS. 2000.\n",
            "\n",
            "|details-end|\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.93      1.00      0.97        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       0.93      1.00      0.96        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       1.00      0.96      0.98        28\n",
            "           7       0.94      0.97      0.96        33\n",
            "           8       1.00      0.84      0.91        43\n",
            "           9       0.94      0.94      0.94        32\n",
            "\n",
            "    accuracy                           0.96       360\n",
            "   macro avg       0.96      0.96      0.96       360\n",
            "weighted avg       0.97      0.96      0.96       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "# (1) 필요한 모듈 import\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split #싸이킷런에 있는 데이터를 train과 test dataset으로 나누어주는 함수 import\n",
        "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
        "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위해 쓰는 코드\n",
        "\n",
        "\n",
        "# (2) 데이터 준비\n",
        "digits = load_digits() #digits 데이터 전체를 불러온다.\n",
        "digits.keys()\n",
        "\n",
        "# (3) 데이터 이해하기\n",
        "digits_data = digits.data #Feature Data 지정하기\n",
        "digits_label = digits.target #Label Data 지정하기\n",
        "\n",
        "digits.target_names #Target Names 출력해 보기\n",
        "print(digits.DESCR) #데이터 Describe 해 보기\n",
        "\n",
        "\n",
        "# (4) train, test 데이터 분리\n",
        "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
        "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다. (어떤 값을 넣어도 무방하다.)\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
        "                                                    digits_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=7)\n",
        "\n",
        "\n",
        "# (5) 모델 학습 및 예측\n",
        "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
        "svm_model.fit(X_train, y_train) # 훈련\n",
        "y_pred = svm_model.predict(X_test) # 예측\n",
        "\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzIxHTscZWaR",
        "outputId": "8442d306-09fd-428d-83f7-b0e721d153f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n",
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            "|details-start|\n",
            "**References**\n",
            "|details-split|\n",
            "\n",
            "- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "  Graduate Studies in Science and Engineering, Bogazici University.\n",
            "- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "  Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "  Electrical and Electronic Engineering Nanyang Technological University.\n",
            "  2005.\n",
            "- Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "  Algorithm. NIPS. 2000.\n",
            "\n",
            "|details-end|\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      1.00      0.98        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       1.00      1.00      1.00        37\n",
            "           5       0.93      1.00      0.97        28\n",
            "           6       1.00      1.00      1.00        28\n",
            "           7       1.00      1.00      1.00        33\n",
            "           8       1.00      0.93      0.96        43\n",
            "           9       1.00      0.97      0.98        32\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "# (1) 필요한 모듈 import\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split #싸이킷런에 있는 데이터를 train과 test dataset으로 나누어주는 함수 import\n",
        "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
        "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위해 쓰는 코드\n",
        "\n",
        "\n",
        "# (2) 데이터 준비\n",
        "digits = load_digits() #digits 데이터 전체를 불러온다.\n",
        "digits.keys()\n",
        "\n",
        "# (3) 데이터 이해하기\n",
        "digits_data = digits.data #Feature Data 지정하기\n",
        "digits_label = digits.target #Label Data 지정하기\n",
        "\n",
        "digits.target_names #Target Names 출력해 보기\n",
        "print(digits.DESCR) #데이터 Describe 해 보기\n",
        "\n",
        "\n",
        "# (4) train, test 데이터 분리\n",
        "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
        "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다. (어떤 값을 넣어도 무방하다.)\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
        "                                                    digits_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=7)\n",
        "\n",
        "\n",
        "# (5) 모델 학습 및 예측\n",
        "sgd_model = SGDClassifier() # 모델 객체 생성\n",
        "sgd_model.fit(X_train, y_train) # 훈련\n",
        "y_pred = sgd_model.predict(X_test) # 예측\n",
        "\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGQwF6_mai08",
        "outputId": "95142199-a5f3-489b-dded-d8df60fc4ba8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n",
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            "|details-start|\n",
            "**References**\n",
            "|details-split|\n",
            "\n",
            "- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "  Graduate Studies in Science and Engineering, Bogazici University.\n",
            "- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "  Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "  Electrical and Electronic Engineering Nanyang Technological University.\n",
            "  2005.\n",
            "- Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "  Algorithm. NIPS. 2000.\n",
            "\n",
            "|details-end|\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.81      1.00      0.89        42\n",
            "           2       0.98      1.00      0.99        40\n",
            "           3       0.91      0.94      0.93        34\n",
            "           4       1.00      0.97      0.99        37\n",
            "           5       0.97      1.00      0.98        28\n",
            "           6       0.96      0.93      0.95        28\n",
            "           7       0.91      0.97      0.94        33\n",
            "           8       0.97      0.79      0.87        43\n",
            "           9       1.00      0.84      0.92        32\n",
            "\n",
            "    accuracy                           0.94       360\n",
            "   macro avg       0.95      0.94      0.95       360\n",
            "weighted avg       0.95      0.94      0.94       360\n",
            "\n"
          ]
        }
      ]
    }
  ]
}